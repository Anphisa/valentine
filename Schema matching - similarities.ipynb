{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, string, nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data for TF-IDF \n",
    "1. Lowercase and apply utf-8 conversion\n",
    "2. Remove the punctuation\n",
    "3. Tokenize the data\n",
    "4. Lemmatize\n",
    "5. Apply stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    table = str.maketrans({key: ' ' for key in string.punctuation})\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    porter_stemmer = PorterStemmer()\n",
    "        \n",
    "    #lowercase applying utf-8 conversion\n",
    "    data = data.casefold()\n",
    "    # remove punctuation\n",
    "    data = data.translate(table) \n",
    "    # tokenize the data\n",
    "    data_tokens = nltk.word_tokenize(data)\n",
    "    # for each token that is not a stopword, first lemmatize and then stem\n",
    "    data_tokens = [porter_stemmer.stem(wordnet_lemmatizer.lemmatize(t, pos=\"v\")) for t in data_tokens \n",
    "                  if t not in stop_words]\n",
    "    \n",
    "    return ' '.join(data_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the columns data match a specific data type\n",
    "data - pandas DataFrame \n",
    "\n",
    "t - python data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_columns(data, t):\n",
    "    columns = data.columns\n",
    "\n",
    "    result = []\n",
    "    for c in columns:\n",
    "           if type(data[c][0]) is t:\n",
    "                result.append(c)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF and cosine similarity between columns of 2 datasets\n",
    "Given 2 datasets, compute the cosine similarity column by column (Each columns from corpus1 with each column for corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_cos_sim_by_col(corpus1, corpus2):\n",
    "    vectorizer = TfidfVectorizer(preprocessor=preprocess)\n",
    "    columns = corpus1.columns\n",
    "    other_columns = corpus2.columns\n",
    "\n",
    "    result = {}\n",
    "    for c0 in columns:\n",
    "        similarities = []\n",
    "#         print(c0)\n",
    "        data0 = corpus1[c0].astype('U').tolist()\n",
    "        for c1 in other_columns:\n",
    "            print('\\t'+c1)\n",
    "            data1 = corpus2[c1].astype('U').tolist()\n",
    "            doc = data0 + data1\n",
    "            vectorizer_train = vectorizer.fit(doc)\n",
    "            X = vectorizer_train.transform(doc)\n",
    "            sim = cosine_similarity(X[0], X[1])\n",
    "            similarities.append(sim[0])\n",
    "        result[c0] = similarities\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF and cosine similarity between rows of 2 columns\n",
    "Given 2 columns, compute the cosine similarity row by row (Each row from columns1 with each row for column2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_cos_sim_by_row(column1, column2):\n",
    "    vectorizer = TfidfVectorizer(preprocessor=preprocess)\n",
    "    \n",
    "    result = []\n",
    "    for data in column1:\n",
    "        corpus = data + column2\n",
    "        vectorizer_train = vectorizer.fit(corpus)\n",
    "        X = vectorizer_train.transform(corpus)\n",
    "        sim = cosine_similarity(X, X)\n",
    "        result.append(sim)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a dictonary to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_csv(dictonary, filename, columns):\n",
    "    try:\n",
    "        with open(filename, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(columns)\n",
    "            for key in list(dictonary):\n",
    "                data = [r[0] for r in dictonary[key]]\n",
    "                writer.writerow(data)\n",
    "    except IOError:\n",
    "        print(\"I/O error\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return similar columns based on the column names\n",
    "Given 2 datasets, return the similar columns based on the column names. The similarity is computed using TF-IDF and cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sim_col(data1, data2):\n",
    "    result = {}\n",
    "    columns = (data1.columns).tolist()\n",
    "    other_columns = (data2.columns).tolist()\n",
    "    corpus = columns + other_columns\n",
    "\n",
    "    vectorizer = TfidfVectorizer(preprocessor=preprocess)\n",
    "    vectorizer_train = vectorizer.fit(corpus)\n",
    "    X = vectorizer_train.transform(corpus)\n",
    "\n",
    "    sim = cosine_similarity(X, X)\n",
    "    A = csr_matrix(sim)   \n",
    "    rows, columns = A.nonzero()\n",
    "    \n",
    "    for r, c in zip(rows, columns):\n",
    "        if r == c:\n",
    "            continue\n",
    "            \n",
    "        if sim[r][c] > 0.5:\n",
    "            result[corpus[r]] = corpus[c]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Jaccard similarity betwen 2 columns\n",
    "Given 2 columns, compute the jaccard similarity (each row from column1 with each row from column2)\n",
    "\n",
    "Return: A matrix of len(column1) x len(column2) elements. Element i,j represents the distance between row i from column1 and row j from column2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim_row(column1, column2):\n",
    "    result = []\n",
    "    for c1 in column1: \n",
    "#         print(c1)\n",
    "        c1 = set(c1)\n",
    "        jds = []\n",
    "        for c2 in column2:\n",
    "            c2 = set(c2)\n",
    "            jds.append(nltk.jaccard_distance(c1, c2))\n",
    "        result.append(jds)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similar numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_num_cols(data1, data2):\n",
    "    str_columns1 = get_type_columns(data1, float)\n",
    "    str_columns1 += get_type_columns(data1, int)\n",
    "    str_columns1 += get_type_columns(data1, np.float64)\n",
    "\n",
    "    str_columns2 = get_type_columns(data2, int)\n",
    "    str_columns2 += get_type_columns(data2, float)\n",
    "    str_columns2 += get_type_columns(data2, np.float64)\n",
    "\n",
    "    sim_cols = filter_sim_col(data1, data2)\n",
    "\n",
    "    for key, value in sim_cols.items():\n",
    "        if len(str_columns1) == 0 and len(str_columns2) > 0:\n",
    "            if key in str_columns2:\n",
    "                return [key, value]\n",
    "        \n",
    "        if key in str_columns1 and value in str_columns2: \n",
    "            return [key, value]\n",
    "        elif key in str_columns2 and value in str_columns1:\n",
    "            return [value , key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_imdb = pd.read_csv('movies3/csv_files/imdb.csv')\n",
    "data_rt = pd.read_csv('movies3/csv_files/rotten_tomatoes.csv')\n",
    "\n",
    "# Clean data\n",
    "data_imdb = data_imdb.fillna(0)\n",
    "data_rt = data_rt.fillna(0)\n",
    "data_rt = data_rt.replace({'Rating': ['N', '.']}, {'Rating': 0})\n",
    "\n",
    "# Store data for future processing \n",
    "data1 = data_imdb\n",
    "data2 = data_rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the similar numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rating', 'Rating']\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = find_sim_num_cols(data1, data2)\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute EMD on the similar colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.331381641581892\n"
     ]
    }
   ],
   "source": [
    "emd = wasserstein_distance(data1[numerical_cols[0]], data2[numerical_cols[1]])\n",
    "print(emd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find non-numerical similar columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'ID', 'Title': 'Title', 'Year': 'Year', 'Director': 'Director', 'Creators': 'Creators', 'Cast': 'Cast', 'Genre': 'Genre', 'Duration': 'Duration', 'ContentRating': 'ContentRating', 'Summary': 'Summary'}\n"
     ]
    }
   ],
   "source": [
    "similar_columns = filter_sim_col(data1, data2)\n",
    "del similar_columns[numerical_cols[0]]\n",
    "\n",
    "print(similar_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Jaccard similarity between 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_jd = jaccard_sim_row(data1['Title'], data2['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the tf-idf cosine similarity\n",
    "\n",
    "Note: not working good for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Title'}\n",
      "Title\n"
     ]
    }
   ],
   "source": [
    "columns = dict((key,value) for key, value in similar_columns.items() if key == 'Title')\n",
    "print(columns)\n",
    "\n",
    "map_sim = {}\n",
    "for k, v in columns.items():\n",
    "    if k == 'Id':\n",
    "        continue\n",
    "    print(k)\n",
    "    result_row = tf_idf_cos_sim_by_row(data1[k], data2[v])\n",
    "    max_val = 0\n",
    "    for r in result_row:\n",
    "        val = (r - np.eye(len(r))).max()\n",
    "        if val > max_val:\n",
    "            max_val = val\n",
    "    print(max_val)\n",
    "    map_sim[k] = max_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
